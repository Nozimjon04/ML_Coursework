# World Bank Contract Awards â€” Machine Learning Coursework

This project analyzes the **World Bank Contract Awards dataset** and builds machine learning models to **predict contract amounts**, supported by a complete **EDAâ†’Preprocessingâ†’Model Trainingâ†’Evaluationâ†’Deployment** workflow.

The solution includes:

- Jupyter Notebook for analysis  
- Data preprocessing pipeline  
- ML model training (3 models)  
- Model evaluation  
- Streamlit multi-page web application  
- Online deployment (Streamlit Cloud)  

---

#  Project Structure

ML_Coursework/
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ data_exploration.ipynb
â”‚ â”œâ”€â”€ data_preprocessing.ipynb
â”‚ â””â”€â”€ evaluation.ipynb
  â””â”€â”€ model_training.ipynb
â”‚
â”œâ”€â”€ streamlit_app/
â”‚ â”œâ”€â”€ app.py
â”‚ â””â”€â”€ pages/
â”‚ â”œâ”€â”€ EDA.py
â”‚ â”œâ”€â”€ Preprocessing.py
â”‚ â”œâ”€â”€ Train_Model.py
â”‚ â””â”€â”€ Evaluation.py
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â””â”€â”€ processed/
â”‚
â”œâ”€â”€ models/ # ignored by Git
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md



---

#  Dataset

The dataset used:

**World Bank â€“ Contract Awards in Investment Project Financing (Since FY 2020)**  
Source: https://financesone.worldbank.org/contract-awards-in-investment-project-financing-since-fy-2020/DS00005

The dataset contains fields such as:

- Region  
- Borrower Country  
- Procurement Category  
- Fiscal Year  
- Supplier  
- Contract Signing Date  
- Contract Amount (Target Variable)
---

# Exploratory Data Analysis (EDA)

Performed using:

- Summary statistics (mean, std, min, max, percentiles)
- Correlation matrix
- Histograms & KDE plots
- Boxplots for outlier inspection
- Scatter plots between numeric features
- Categorical frequency charts
- Missing values heatmap  
- Duplicate row detection

EDA is available in:

- Streamlit page: `/EDA`

---

#  Data Preprocessing

Steps included:

### Handling missing values
- Numeric â†’ median replacement  
- Categorical â†’ `"Unknown"`  

### Outlier removal  
- IQR (Interquartile Range) filtering on numeric features  

### Feature engineering  
- Extract year and month from `Contract Signing Date`  
- Create `Is_Recent` feature based on fiscal year  

### Encoding categorical features  
- One-hot encoding (low cardinality)
- Ordinal encoding (high cardinality)

### Scaling  
- StandardScaler applied to numeric columns

### Train-test split  
Handled in the training page (configurable split %).

File:  
- Streamlit: `/Preprocessing`

---
# Model Training

Three machine learning models:

1. **Linear Regression**  
2. **Random Forest Regressor**  
3. **XGBoost Regressor**

### Hyperparameter tuning (via Streamlit sliders):
- `n_estimators`, `max_depth`, `min_samples_split` (Random Forest)  
- `learning_rate`, `n_estimators`, `max_depth` (XGBoost)

### Target transformation
- Optional `log1p()` transformation for improved performance on skewed data.

### Outputs:
- RMSE  
- MAE  
- RÂ² score  
- Saved trained model (`.joblib`)  
- Downloadable model file  

Files:
- `notebooks/Model_Training.ipynb`
- Streamlit: `/Train Model`

---

# Model Evaluation

Evaluation metrics:

- Root Mean Squared Error (RMSE)  
- Mean Absolute Error (MAE)  
- RÂ² Score

Visualizations include:

- Actual vs Predicted scatter plot  
- Distribution of residuals  
- Feature importance for tree models  

File:
- Streamlit: `/Evaluation`

---

# Deployment (Streamlit Cloud)

The application is deployed at:

ðŸ‘‰ **LIVE APP:** *https://mlcoursework-hycmb7wemglsee9hqeaj9h.streamlit.app/*  

Start the app locally:

```bash
streamlit run streamlit_app/app.py




